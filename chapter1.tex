\documentclass[lambda.tex]{subfiles}
\begin{document}

\paragraph{Введение.} ~\\

\begin{tcolorbox}
VODAVODAVODA
$\rb$
$\rbm$
\end{tcolorbox}

Опишем лямбда исчисление формально.

Множество лямбда-термов строится из бесконечного множества переменных $\mathcal{V}$ использованием аппликации и абстракции:
\[\mathcal{V} = \{ v, v', v'', v''' \dots \}\]

При этом, говоря формально:
\begin{align*}
x \in \mathcal{V} & \implies x \in \Lambda & \text{(Переменная является лямбда-термом)}\\
M, N \in \mathcal{V} & \implies M N \in \Lambda & \text{(Аппликация является лямбда-термом)}\\
M \in \mathcal{V}, v \in \mathcal{V} & \implies \lambda v.M \in \Lambda & \text{(Абстракция является лямбда-термом)}
\end{align*}

Или же, используя БНФ:
\begin{align*}
V &::= v|V'\\
\Lambda &::= V | (\Lambda\ \Lambda) | ( \lambda V . \Lambda )
\end{align*}

В дальнейшем условимся, что:
\begin{itemize}
\item\(x,y,z,\dots - \text{произвольные переменные.}\)
\item\(M,N,L,\dots - \text{произвольные лямбда термы.}\)
\item Скобки верхнего уровня опускаются.
\item Аппликация правоассоциативна, т.е.\\
\[F\ M_1 \ M_2 \ \dots\ M_n \equiv (\dots((F\ M_1)\ M_2)\ \dots\ M_n)\]
\item Допустима абстракция сразу по нескольким переменным
\[\lambda x_1 \ x_2 \ \dots\ x_n .M \equiv \lambda x_1 .(\lambda x_2 .\ \dots\ (\lambda x_n .M))\]
\end{itemize}

\paragraph{Свободные и связанные переменные} % (fold)
\label{par:free_and_bound} ~\\
Множеством свободных переменных терма $N$ называется $FV(N)$, индуктивно определяемое по следующим правилам:
\begin{align*}
FV(x) &\equiv \{x\}\\
FV(M\ N) &\equiv FV(M)\cup FV(N)\\
FV(\lambda x.N) &\equiv FV(N)\setminus\{x\}
\end{align*}

Мы будем называть переменную связанной, если она не принадлежит множеству свободных. Множество связанных переменных терма $N$ принято обозначать как $BV(N)$ Заметим, что переменная связана, если она образует абстракцию.

Мы будем называть терм $M$ закрытым (или комбинатором), если\\ \(FV(M) \equiv \varnothing\). Множество комбинаторов обозначим как $\Lambda^\circ$. Существует раздел математики, тесно связанный с $\lambda$-исчислением - комбинаторная логика. Она изучает комбинаторы и вычисления построенные на них. В комбинаторной логике вводится несколько стандартных комбинаторов:

\begin{align*}
	&Sxyz = xz(yz)\\
	&Kxy = x\\
    &Ix = x\\
	% TODO: больше комбинаторов Богу комбинаторов!
\end{align*}
%TODO: task: дать определение комбинаторам лямбда термами, выразить I через S и K

% paragraph свободные_и_связанные_переменные (end)

\paragraph{$\alpha$-конверсия} % (fold)
~\\
\label{par:aplha conversion}
Введем на $\Lambda$ отношение эквивалентности, задаваемое следующим образом:
\begin{align*}
\forall P.P &=_\alpha P\\
\lambda x.P &=_\alpha \lambda y.P[x:=y] \text{ если } y \not\in FV(P)
\end{align*}

Это отношение носит название $\alpha$-эквивалентность. Так же напишем некоторые аксиомы для этого отношения:

\begin{align*}
M &=_\alpha M\\
M =_\alpha N &\Rightarrow N =_\alpha M\\
M =_\alpha N, N =_\alpha L &\Rightarrow M =_\alpha L\\
M =_\alpha M' &\Rightarrow M\ Z =_\alpha M'\ Z\\
M =_\alpha M' &\Rightarrow Z\ M =_\alpha Z\ M'\\
M =_\alpha M' &\Rightarrow \lambda x.M =_\alpha \lambda x.M'
\end{align*}
Если $M =_\alpha N$, иногда также пишут $\lambda\models M =_\alpha N$

%TODO: перепилить как правила вывода

Обобщая определения выше, $M$ и $N$ равны (альфа-эквивалентны), если можно получить один из другого, путем замены имен связанных переменных. Любые два равных терма в одинаковом контексте так же будут равны.
%Это так ты про альфа-эквивалентность коротко? Вот пидор.
%[Д] Тип да. Так лучше?

Сам процесс замены имени носит название $\alpha$-конверсия и определяется следующим образом:
\begin{equation*}
\lambda x.M \rightarrow_\alpha \lambda y.(M[x := y]) \text { если } y \not\in FV(M)\tag{$\alpha$}
\end{equation*}
% запили как с бетой
% DONE

% paragraph aplha conversion (end)

\paragraph{Подстановки} % (fold)
\label{par:substitution}
~\\
Результат подстановки $N$ вместо всех свободных вхождений $x$ в $M$ обозначим $M[x := N]$ и определим как:
\begin{align*}
x[x := N] &\equiv N\\
y[x := N] &\equiv y\ (\text{если } x \neq y)\\
(M_1 \ M_2 )[x := N] &\equiv ((M_1 [x := N])\ (M_2 [x := N]))\\
(\lambda y.M)[x := N] &\equiv (\lambda y.M[x := N])
\end{align*}

%TODO: Что-то про Variable convention

Условимся, что подстановка всегда выполняется корректно, то есть, заменяемая переменная никогда не является связанной ни в каких внутренних термах. Этой ситуации всегда можно избежать заменой имен во внутреннем терме. Например для следующей подстановки предварительно произведем замену имени во внутренней лямбды.
\[\lambda a.\lambda b.a\ b[a := b] = \lambda a.(\lambda b.a\ b[b := b'])[a := b] = \lambda b.\lambda b'.b\ b'\]

В силу этого условия допускается некая вольность в обращении с подстановкой, что делает рассуждения компактнее без ущерба сути, пусть и с некой меньшей долей формализма.

\newtheorem{lemma}{Лемма}

\begin{lemma}
\[(\lambda x_1 \ x_2 \ \dots\ x_n .M)\ X_1 \ X_2 \ \dots\ X_n \equiv M[x_1 := X_1 ][x_2 := X_2]\dots[x_n := X_n ]\]
\end{lemma}
\begin{proof}
Пусть $M' = \lambda x_2 \dots x_n .M$. По аксиоме $(\beta)$ мы имеем
\[(\lambda x_1 .M')\ X_1 \ X_2 \ \dots\ X_n \equiv M'[x_1 := X_1 ] X_2 \ \dots\ X_n\]
Дальнейшее равенство получаем индукцией по связанным переменным.
\end{proof}

% paragraph substitution (end)

Теперь мы готовы описать $\lambda$-исчисление как формальную теорию.\\

\paragraph{$\beta$-редукция} % (fold)
\label{par:beta reduction}
~\\
Основная схема $\lambda$-исчисления
\begin{equation*}
\forall M, N \in \Lambda : (\lambda x.M)\ N = M[x := N]\tag{$\beta$}
\end{equation*}

Имея аксиому ($\beta$), опишем изменеие порядка выполнения перестановок:
\begin{lemma}{о подстановке}
\begin{equation*}
	M[x := N_1][y := N_2] \equiv M[y := N_2][x := N_1[y := N_2]]
\end{equation*}
\end{lemma}
\begin{proof}
	Индукция по структуре терма M: \\
	\begin{itemize}
		\item M $\in$ $\mathcal{V}$ По определению подстановки имеем три случая
		\begin{itemize}
		% TODO: стрелка => !!!!!!!!!!!!!!!!!!!!!!!!!!!!!
		 	\item $M = x$ => $N_1[y := N_2] \equiv N_1[y := N_2]$
		 	\item $M = y$ => $N_2 \equiv N_2$ ($x\not\in FV(N_2)$)
		 	\item $M = z$ ($z \neq x, y$) => $z \equiv z$
		 \end{itemize}
		 \item M = $\lambda z.M_1$
		 В силу соглашений, можно предположить, что $z \neq x,y$ и $z\not\in FV(N_1) \cup FV(N_2)$
		 \begin{align*}
		 			 (\lambda z.M_1)[x := N_1][y := N_2] 
		 			 &\equiv \lambda z.M_1[x := N_1][y := N_2]\\
		 			 &\equiv \lambda z.M_1[y := N_2][x := N_1[y := N_2]] \\
		 			 &\equiv (\lambda z.M_1)[y := N_2][x := N_1[y := N_2]]
		 \end{align*}
		 Второе равенстро полученно из индукционного предположения
		 \item $M = M_1 M_2$
		 По индукции лемма верна для $M_1$ и $M_2$, далнейшее равенство очевидно
	\end{itemize}
\end{proof}


Однократное применение аксиомы ($\beta$) будем называть $\beta$-редукцией и обозанчать как ($\rb$). Место, где можно применить аксиому ($\beta$) будем называть редексом. 
Применение аксиомы ($\beta$) ноль или более раз обозначим как $\rbm$ (транзитивное замакание $\rb$)

Также введем отношение $\beta$-эквивалентности, которое обозначим как $=_\beta$
%TODO: корректность этой фигни

Любое вычисление представляет собой некоторое колличество шагов $\beta$-редукции.

Вычисления заканчиваются, когда в терме не остается редексов, будем говорить, что такие термы находятся в нормалной форме.

Стоит заметить, что $\beta$-редукция, хотя и называется редукцией, не всегда сокращает терм, и тем более, не всегда делает терм проще. Как пример плохого, можно привести следующий терм:
\begin{equation*}
	\omega = (\lambda x.xx)(\lambda x.xx)
\end{equation*}
Такая конструкция за один шаг редуцируется в себя. Очевидно, что у $\omega$ никакая цепочка преобразований не приведет к нормальной форме, тогда возникает вопрос, для каких термов существует нормальная форма, зависит ли она от порядка применения ($\beta$) и любой ли порядок ведет к нормальной форме. Мы вернемся к этой теме позже, а пока дополним наше $\lambda$-исчисление еще одной аксиомой
\begin{equation*}
	\lambda x.Mx \equiv M \text{ если }x \not\in FV(M) \tag{$\eta$}
\end{equation*}

% paragraph beta reduction (end)

\paragraph{Неподвижная точка} % (fold)
\label{par:fix point}
~\\

На данном этапе мы можем относительно свободно строить различные термы, однако особый подход требуется для описания рекурсивный функций, о чем сейчас и пойдет речь. Для бестипового лямбда-исчисления справедлива следующая теорема:
% [Теорема о неподвижной точке]
\newtheorem*{fixpoint}{Теорема о неподвижной точке}
\begin{fixpoint}
\begin{align*}
&(i)\ \ \forall F. \exists X. (F\ X = X) \\
&\text{Более того, существует комбинатор, находящий $X$}\\
% &\text{}\\
&\ \ \ \ \ Y = \lambda f.(\lambda x.f\ (x\ x)) (\lambda x.f\ (x\ x))\\
&(ii)\ \forall F.(Y\ F=F\ (Y\ F))
\end{align*}
\end{fixpoint}

\begin{proof}
~\\
Определим $W = \lambda x.F(x\ x)$ и $X = W\ W$ тогда
\begin{align*}
X \equiv W\ W \equiv (\lambda x.F(x\ x))W \rightarrow_\beta\\
F\ (W\ W) \equiv F X
\end{align*}
Аналогично
\begin{align*}
&Y\ F \rightarrow_\beta\\
&(\lambda x.F\ (x\ x)) (\lambda f.(\lambda x.F\ (x\ x))) \rightarrow_\beta\\
&F\ ((\lambda f.(\lambda x.F\ (x\ x))) (\lambda f.(\lambda x.F\ (x\ x)))) \equiv F\ (Y\ F)
\end{align*}
\end{proof}
% paragraph fix point (end)

\paragraph{Ленивый и аппликативный порядки редукции} % (fold)
\label{par:lazy and energic reduction}

Как вы уже видели, не все термы имеют нормальную форму. Рассмотрим следующий терм:
\begin{equation*}
	N = (\lambda x y.y) ((\lambda x.xx)(\lambda x.xx)) M
\end{equation*}
В этом терме два редекса, можно произвести $\beta$-редукцию в двух разных местах:
\begin{align*}
	N &\rb M\\
	N &\rb (\lambda x y.y) ((\lambda x.xx)(\lambda x.xx)) M
\end{align*}
В первом случае мы проредуцировали внешний редекс, во втором внутренний (который оказался уже знакомым термом $\omega$, редуцирующимся в себя), как вы могли заметить, мы не сможем придти к нормальной форме $N$ редуцируя внутренний терм, когда как единственная редукция внешнего терма приводит $N$ к его нормальной форме. Это значит, что если нормальная форма существует, к ней не обязательно ведет любой порядок редукции. То, в каком порядке мы производим редукцию, определяет стратегию вычислений. Выделяют различные стратегии, мы же затронем две из них: аппликативную (соответствующей энергичным вычислениям в языках программирования) и ленивую.
При аппликативной стратегии, мы редуцируем термы справа нелево, изнутри наружу. Это соответствует вычислению значения аргументов перед вызовом функции.
Ленивые вычисления предполагают редукцию самого левого внешнего терма.

Существует утверждение(Карри) о том, что если у терма существует нормальная форма, то к ней можно придти при помощи ленивой стратегии вычислений. Не будем приводить доказательство этого факта ввиду его трудоемкости. 
% paragraph Church-Rosser (end)

\end{document}